"""
2-Tier Hybrid Analyzer for MarketPulse-Reg

Tier 1 (Gatekeeper): Fast filtering with gemini-2.5-flash-lite
Tier 2 (Analyst): Deep analysis with gemini-3-flash-preview for important news only
"""

import os
import json
import time
import logging
from typing import Dict, Any, Optional
from dotenv import load_dotenv
import google.generativeai as genai
from google.generativeai.types import GenerationConfig

# Load env
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env'))

# Import settings
from config.settings import (
    MODEL_FILTER_ID, 
    MODEL_ANALYZER_ID, 
    MODEL_ANALYZER_FALLBACK,
    IMPORTANCE_THRESHOLD,
    API_CALL_DELAY
)

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")


class HybridAnalyzer:
    """2-Tier Hybrid Analyzer with Gatekeeper + Analyst pipeline."""
    
    def __init__(self):
        if not GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEY is not set in .env")
        
        genai.configure(api_key=GEMINI_API_KEY)
        
        self.filter_model = MODEL_FILTER_ID
        self.analyzer_model = MODEL_ANALYZER_ID
        self.analyzer_fallback = MODEL_ANALYZER_FALLBACK
        self.importance_threshold = IMPORTANCE_THRESHOLD
        
    def _call_api(self, model_name: str, prompt: str, max_retries: int = 3) -> Optional[str]:
        """Call Gemini API with retry logic."""
        base_delay = 10
        model = genai.GenerativeModel(model_name)
        
        for attempt in range(max_retries):
            try:
                response = model.generate_content(
                    prompt,
                    generation_config=GenerationConfig(
                        response_mime_type="application/json"
                    )
                )
                
                if response.text:
                    return response.text
                return None
                
            except Exception as e:
                error_str = str(e)
                if "429" in error_str or "RESOURCE_EXHAUSTED" in error_str:
                    delay = base_delay * (attempt + 1)
                    logger.warning(f"Rate Limit hit. Retrying in {delay}s... (Attempt {attempt+1}/{max_retries})")
                    time.sleep(delay)
                elif "404" in error_str or "NOT_FOUND" in error_str:
                    logger.error(f"Model {model_name} not found")
                    # Fallback instantly if model name is wrong
                    return None
                else:
                    logger.error(f"API Error ({model_name}): {error_str[:200]}")
                    # If it's a critical error, maybe don't retry immediately or handle differently
                    # But for now, we try/catch loop
                    time.sleep(5)
        
        logger.error("Failed after max retries")
        return None

    def filter(self, title: str, description: str, agency_name: str) -> Optional[Dict[str, Any]]:
        """
        Tier 1: Gatekeeper - Quick relevance filtering.
        Uses only title + description to save tokens.
        """
        prompt = f"""
        You are a news relevance filter for a Korean commercial bank's risk management team.
        
        **Task**: Determine if this news is relevant to "Korean commercial banks' risk management" and assign an importance score.
        
        **Input**:
        - Source: {agency_name}
        - Title: {title}
        - Summary: {description}
        
        **Scoring Guidelines (Based on 'Banking Business Impact' & 'Actionability')**:
        
        **High (Score 4-5): Immediate Strategy Revision / ALCO Agenda (Must Act)**
        *Criteria: If the news requires an ALCO or Risk Committee meeting tomorrow, or impacts the following:*
        1. **4 Pillars**:
           - **Loan (ì—¬ì‹ )**: DSR/LTV changes, Provisioning rules, Underwriting guidelines.
           - **Deposit (ìˆ˜ì‹ )**: Rate disclosure rules, liquidity coverage requirements, funding competition limits.
           - **Compliance (ì¤€ë²•)**: Bank Act amendments, Internal Control (Book of Responsibilities), Consumer Protection Act.
           - **Capital (ìž¬ë¬´)**: BIS ratio rules, Dividend restrictions, LCR/NSFR changes.
        2. **Market/Biz Impact**:
           - **Macro**: BOK Base Rate decisions, Major liquidity supply.
           - **New Biz**: Permission for new ventures (Platform, non-financial), Restrictions on core earnings (Interest income).
           - **Spillover**: Major crises in securities/insurance sectors affecting bank subsidiaries or stability.
        
        **Moderate (Score 3): Monitoring / Watch List**
        *Criteria: General market monitoring or indirect references.*
        - **Market**: Exchange rate/Interest rate trends (without policy shifts).
        - **Indirect**: Regulations for other sectors (Card/Insurance) with minor spillover to banks.
        - **Reports**: Household debt stats (monthly), Delinquency rate trends (if not crisis level).

        **Low (Score 1-2): Routine / Irrelevant**
        *Criteria: Administrative or unrelated.*
        - **Routine**: Bond auctions, weekly schedules, holiday notices.
        - **Admin**: Personnel news, Awards, MOUs without binding policy changes.
        - **Irrelevant**: Exclusive issues of other sectors (Savings banks, Pawn shops) with zero bank impact.
        
        **Output** (JSON only):
        {{
            "is_relevant": boolean, (True if Score >= 1, False if completely unrelated like 'Ads')
            "importance_score": integer (1-5)
        }}
        """
        
        response_text = self._call_api(self.filter_model, prompt)
        
        if response_text:
            try:
                return json.loads(response_text)
            except json.JSONDecodeError:
                logger.error(f"Failed to parse filter response: {response_text[:100]}")
                return None
        return None

    def analyze(self, title: str, full_content: str, agency_name: str) -> Optional[Dict[str, Any]]:
        """
        Tier 2: Analyst - Deep analysis for important news.
        Uses full article content.
        """
        prompt = f"""
        # Role
        ë‹¹ì‹ ì€ ì‹œì¤‘ì€í–‰ ì „ëžµê¸°íšë¶€(CSO) ë° ë¦¬ìŠ¤í¬ê´€ë¦¬ë¶€(CRO) ì†Œì† ìˆ˜ì„ ë¶„ì„ê°€ìž…ë‹ˆë‹¤. 
        ë‹¹ì‹ ì˜ ìž„ë¬´ëŠ” ê¸ˆìœµë‹¹êµ­ì˜ ë³´ë„ìžë£Œë¥¼ ë¶„ì„í•˜ì—¬ 'ì€í–‰ ì‹¤ë¬´ ë° ë¦¬ìŠ¤í¬'ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ í‰ê°€í•˜ê³ , ê²½ì˜ì§„ì´ ì¦‰ì‹œ ì˜ì‚¬ê²°ì •í•  ìˆ˜ ìžˆëŠ” ë¦¬í¬íŠ¸ë¥¼ ìž‘ì„±í•˜ëŠ” ê²ƒìž…ë‹ˆë‹¤.

        # Core Philosophy (Action-Focused)
        "ì´ ë‰´ìŠ¤ë¡œ ì¸í•´ ì€í–‰ì´ ë‚´ë¶€ ê·œì •, íŒë§¤ ì ˆì°¨, ìžë³¸ ê³„íšì„ ìˆ˜ì •í•´ì•¼ í•˜ëŠ”ê°€?"
        - ì€í–‰ì˜ 4ëŒ€ ìš”ì†Œ[ì—¬ì‹ (ëŒ€ì¶œ), ìˆ˜ì‹ (ì˜ˆê¸ˆ), ì»´í”Œë¼ì´ì–¸ìŠ¤(ì¤€ë²•), ìž¬ë¬´(ìžë³¸)]ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ì£¼ë©´ ë¬´ì¡°ê±´ [High]ìž…ë‹ˆë‹¤.
        - ë‹¨ìˆœ ì¸ì‚¬, ë™ì •, íƒ€ ì—…ê¶Œ(ì¦ê¶Œ/ë³´í—˜ ë‹¨ë…) ì†Œì‹ì€ [Low]ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.

        # Constraints
        - ìŠ¤íƒ€ì¼: ì´ëª¨ì§€ ì‚¬ìš© ì ˆëŒ€ ê¸ˆì§€, ëª…ì‚¬í˜• ì¢…ê²°(~í•¨, ~ìž„) ì‚¬ìš©.
        - í†¤ì•¤ë§¤ë„ˆ: ëƒ‰ì² í•˜ê³  ì „ë¬¸ì ì¸ ë¦¬ì„œì¹˜ ë¦¬í¬íŠ¸ ìŠ¤íƒ€ì¼.
        - ë¦¬ìŠ¤í¬ ë¶„ë¥˜: ë°˜ë“œì‹œ [ì‹ ìš©, ì‹œìž¥, ìš´ìš©, ìœ ë™ì„±, ê¸ˆë¦¬, ê¸°íƒ€] ì¤‘ í•´ë‹¹ë˜ëŠ” ê²ƒì„ ëª¨ë‘ ì„ íƒí•˜ì‹­ì‹œì˜¤.

        # Output Format (Strict JSON)
        {{
            "published_date": "YYYY-MM-DD",
            "source": "{agency_name}",
            "importance": {{
                "score": 1-5,
                "level": "High/Medium/Low",
                "reason": "ì¤‘ìš”ë„ íŒë‹¨ ê·¼ê±° (ì€í–‰ ì‹¤ë¬´ ê´€ì ) - 50ìž ì´ë‚´"
            }},
            "classification": {{
                "pillars": ["ì—¬ì‹ ", "ìˆ˜ì‹ ", "ì»´í”Œë¼ì´ì–¸ìŠ¤", "ìž¬ë¬´" ì¤‘ í•´ë‹¹ í•­ëª© ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥],
                "risk_tags": ["ì‹ ìš©", "ì‹œìž¥", "ìš´ìš©", "ìœ ë™ì„±", "ê¸ˆë¦¬", "ê¸°íƒ€" ì¤‘ í•´ë‹¹ ë¦¬ìŠ¤í¬ ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥]
            }},
            "content": {{
                "title": "ë³´ë„ìžë£Œ í•µì‹¬ ì œëª© (30ìž ì´ë‚´)",
                "key_points": ["í•µì‹¬ ë‚´ìš© ìš”ì•½ 1", "í•µì‹¬ ë‚´ìš© ìš”ì•½ 2", "í•µì‹¬ ë‚´ìš© ìš”ì•½ 3"],
                "impact_analysis": "ì€í–‰ ë¹„ì¦ˆë‹ˆìŠ¤ ë° ê·œì œ í™˜ê²½ì— ë¯¸ì¹˜ëŠ” ì‹¬ì¸µ ì˜í–¥ ë¶„ì„ (ìµœëŒ€ 3ë¬¸ìž¥)",
                "action_items": ["ë‚´ì¼ ì˜¤ì „ê¹Œì§€ ì‹¤í–‰ ë˜ëŠ” ê²€í† í•´ì•¼ í•  êµ¬ì²´ì  ì¡°ì¹˜ 1", "ë‚´ì¼ ì˜¤ì „ê¹Œì§€ ì‹¤í–‰ ë˜ëŠ” ê²€í† í•´ì•¼ í•  êµ¬ì²´ì  ì¡°ì¹˜ 2"]
            }}
        }}

        # Input Text
        Title: {title}
        Source: {agency_name}
        Content:
        {full_content[:3000]}
        """
        
        # Try primary model
        response_text = self._call_api(self.analyzer_model, prompt)
        
        # Fallback if primary fails
        if not response_text:
            logger.warning(f"Primary model {self.analyzer_model} failed. Trying fallback {self.analyzer_fallback}")
            response_text = self._call_api(self.analyzer_fallback, prompt)
        
        if response_text:
            try:
                # Remove Markdown code block if present
                clean_text = response_text.replace('```json', '').replace('```', '').strip()
                data = json.loads(clean_text)
                
                # Transform to DB schema format
                return {
                    "summary": data["content"]["key_points"],
                    "impact_analysis": data["content"]["impact_analysis"],
                    "action_items": data["content"]["action_items"],
                    "risk_level": data["importance"]["level"],
                    "risk_score": data["importance"]["score"],
                    "risk_tags": data["classification"]["risk_tags"],
                    "pillars": data["classification"]["pillars"],
                    "analyzed_by": self.analyzer_model # Keep track of which model was used
                }
            except (json.JSONDecodeError, KeyError) as e:
                logger.error(f"Failed to parse analysis response: {e}, Text: {response_text[:100]}")
                return None
        return None

    def _is_personnel_announcement(self, title: str, agency_name: str) -> bool:
        """
        Check if the article is a personnel announcement from key agencies.
        Personnel announcements from any agency are HIGH importance.
        """
        # Key agencies - ALL agencies we track
        key_agencies = ['ê¸ˆìœµê°ë…ì›', 'ê¸ˆìœµìœ„ì›íšŒ', 'ê¸°íšìž¬ì •ë¶€', 'í•œêµ­ì€í–‰', 'FSS', 'FSC', 'MOEF', 'BOK']
        
        # Personnel-related keywords (expanded)
        personnel_keywords = [
            'ì¸ì‚¬', 'ì¸ì‚¬ë°œë ¹', 'ì¸ì‚¬ì´ë™', 'ìž„ëª…', 'ì·¨ìž„', 'ë°œë ¹', 
            'ìž„ì›', 'ìž„ì› ì¸ì‚¬', 'ë¶€ì›ìž¥', 'ì›ìž¥', 'êµ­ìž¥', 'ì‹¤ìž¥', 'ë¶€ìž¥', 'íŒ€ìž¥', 'ë¶€ì„œìž¥',
            'ìŠ¹ì§„', 'ì „ë³´', 'ë³´ì§', 'ê°œíŽ¸', 'ì¡°ì§ê°œíŽ¸', 'ì¡°ì§ ê°œíŽ¸'
        ]
        
        # Check if agency is relevant
        is_key_agency = any(agency in agency_name for agency in key_agencies)
        
        # Check if title contains personnel keywords
        has_personnel_keyword = any(keyword in title for keyword in personnel_keywords)
        
        return is_key_agency and has_personnel_keyword

    def _apply_keyword_safeguards(self, title: str, current_score: int) -> int:
        """
        Apply rule-based safeguards to ensure important keywords are not undervalued by AI.
        Reads rules from config/safeguard_keywords.json.
        """
        try:
            config_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'config', 'safeguard_keywords.json')
            if not os.path.exists(config_path):
                return current_score
                
            with open(config_path, 'r', encoding='utf-8') as f:
                safeguards = json.load(f)
            
            new_score = current_score
            
            # Check High Importance (Score 5)
            for keyword in safeguards.get('high_importance', {}).get('keywords', []):
                if keyword in title:
                    if new_score < 5:
                        logger.info(f"ðŸ›¡ï¸ Safeguard triggered (High): '{keyword}' found. Boosting score {current_score} -> 5")
                        return 5
            
            # Check Medium Importance (Score 4)
            for keyword in safeguards.get('medium_importance', {}).get('keywords', []):
                if keyword in title:
                    if new_score < 4:
                        logger.info(f"ðŸ›¡ï¸ Safeguard triggered (Medium): '{keyword}' found. Boosting score {current_score} -> 4")
                        new_score = 4
                        
            return new_score
            
        except Exception as e:
            logger.error(f"Error applying safeguards: {e}")
            return current_score

    def process(self, article: Dict[str, Any], agency_name: str, category: str = 'press_release') -> Dict[str, Any]:
        """
        Main pipeline: Filter -> Analyze (if important)
        
        Returns combined result with filter and analysis data.
        """
        title = article.get('title', '')
        description = article.get('description') or article.get('content', '')[:200] or title
        full_content = article.get('content') or title
        
        # Default values
        is_relevant = False
        importance_score = 0
        filter_status = "OK"

        # Step 1: Gatekeeper
        filter_result = self.filter(title, description, agency_name)
        time.sleep(API_CALL_DELAY)  # Rate limit protection
        
        if filter_result:
            is_relevant = filter_result.get('is_relevant', False)
            importance_score = filter_result.get('importance_score', 0)
        else:
            logger.warning(f"Filter failed for: {title[:50]}")
            filter_status = "ERROR"

        # ðŸ›¡ï¸ Apply Keyword Safeguards (Override AI Score)
        original_score = importance_score
        importance_score = self._apply_keyword_safeguards(title, original_score)
        
        # If score was boosted, ensure it's marked as relevant
        if importance_score > original_score:
            is_relevant = True
        
        # Build result
        result = {
            "is_relevant": is_relevant,
            "importance_score": importance_score,
            "filter_status": filter_status
        }
        
        # Step 2: Analyst (only for important news)
        # Check if score is high enough (Threshold is usually 3)
        if is_relevant and importance_score >= self.importance_threshold:
            logger.info(f"Proceeding to Tier 2 analysis (Score: {importance_score}): {title[:40]}...")
            
            analysis = self.analyze(title, full_content, agency_name)
            time.sleep(API_CALL_DELAY)  # Rate limit protection
            
            if analysis:
                result.update(analysis)
                result["analysis_status"] = "ANALYZED"
                
                # If safeguard boosted complexity, ensure risk_score matches
                if result.get("risk_score", 0) < importance_score:
                    result["risk_score"] = importance_score
                    if importance_score >= 5:
                        result["risk_level"] = "High"
                    elif importance_score == 4:
                         # Don't downgrade High to Medium, but upgrade Low to Medium
                        if result.get("risk_level") == "Low":
                            result["risk_level"] = "Medium"

                logger.info(f"Analyzed successfully (Model: {self.analyzer_model}): {title[:40]}")
            else:
                result["analysis_status"] = "ANALYSIS_FAILED"
                logger.warning(f"Analysis failed: {title[:40]}")
        else:
            result["analysis_status"] = "SKIPPED"
            logger.info(f"Filtered out (Score: {importance_score}, Relevant: {is_relevant}): {title[:40]}")
        
        return result


# Backward compatibility alias
RegulationAnalyzer = HybridAnalyzer


if __name__ == "__main__":
    analyzer = HybridAnalyzer()
    logger.info("HybridAnalyzer initialized successfully.")
